{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\serge\\miniforge3\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\serge\\miniforge3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\serge\\miniforge3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.6/10.2 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.3/10.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 18.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 46.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.30.1 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.50.3\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\serge\\miniforge3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\serge\\miniforge3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\serge\\miniforge3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification, ViTImageProcessor, pipeline\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Словарь для сопоставления классов с числовыми метками\n",
    "LABEL_MAP = {\n",
    "    \"AK\": 0, \"BCC\": 1, \"BKL\": 2, \"DF\": 3, \"MEL\": 4, \"NV\": 5, \"SCC\": 6, \"VASC\": 7\n",
    "}\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Загружает модель из указанного пути.\"\"\"\n",
    "    model = AutoModelForImageClassification.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "def evaluate_single_image(image_path, model_path):\n",
    "    \"\"\"\n",
    "    Оценивает одно изображение, используя указанную модель.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Путь к изображению.\n",
    "        model_path (str): Путь к модели.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Предсказанный класс и уверенность модели.\n",
    "    \"\"\"\n",
    "    # Загрузка модели и процессора\n",
    "    model = load_model(model_path)\n",
    "    feature_extractor = ViTImageProcessor.from_pretrained(model_path)\n",
    "\n",
    "    # Загрузка изображения\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Создание конвейера для классификации изображений\n",
    "    eval_pipeline = pipeline(\"image-classification\", model=model, feature_extractor=feature_extractor)\n",
    "\n",
    "    # Получение предсказания\n",
    "    outputs = eval_pipeline(image)\n",
    "    predicted_label = outputs[0]['label']\n",
    "    \n",
    "    # Извлечение имени класса из LABEL_MAP\n",
    "    class_name = predicted_label.split('_')[-1]  # Предполагается формат 'LABEL_INDEX'\n",
    "    mapped_class = LABEL_MAP.get(class_name, class_name)\n",
    "    \n",
    "    print(f\"Predicted Label: {mapped_class} (Raw: {predicted_label})\")\n",
    "    print(f\"Confidence: {outputs[0]['score']:.4f}\")\n",
    "    \n",
    "    return mapped_class, outputs[0]['score']\n",
    "\n",
    "def evaluate_folder_images(folder_path, model_path):\n",
    "    \"\"\"\n",
    "    Оценивает все изображения в папке, используя указанную модель.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Путь к папке с изображениями.\n",
    "        model_path (str): Путь к модели.\n",
    "    \n",
    "    Returns:\n",
    "        list: Список кортежей (имя файла, предсказанный класс, уверенность).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    model = load_model(model_path)\n",
    "    feature_extractor = ViTImageProcessor.from_pretrained(model_path)\n",
    "    eval_pipeline = pipeline(\"image-classification\", model=model, feature_extractor=feature_extractor)\n",
    "\n",
    "    # Обработка всех изображений в папке\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            outputs = eval_pipeline(image)\n",
    "            predicted_label = outputs[0]['label']\n",
    "            class_name = predicted_label.split('_')[-1]\n",
    "            mapped_class = LABEL_MAP.get(class_name, class_name)\n",
    "            confidence = outputs[0]['score']\n",
    "            \n",
    "            print(f\"File: {filename}, Predicted Label: {mapped_class}, Confidence: {confidence:.4f}\")\n",
    "            results.append((filename, mapped_class, confidence))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Пример использования:\n",
    "# 1. Для одного изображения:\n",
    "# evaluate_single_image(\"path/to/image.jpg\", \"path/to/model\")\n",
    "\n",
    "# 2. Для папки с изображениями:\n",
    "# evaluate_folder_images(\"path/to/folder\", \"path/to/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 7 (Raw: VASC)\n",
      "Confidence: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 0.9994364380836487)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_single_image(\"pic/1.jpeg\", \"checkpoint-12670\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geffnet in c:\\users\\serge\\miniforge3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from geffnet) (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\serge\\miniforge3\\lib\\site-packages (from geffnet) (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch>=1.4->geffnet) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch>=1.4->geffnet) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch>=1.4->geffnet) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch>=1.4->geffnet) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch>=1.4->geffnet) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch>=1.4->geffnet) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torch>=1.4->geffnet) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from sympy==1.13.1->torch>=1.4->geffnet) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torchvision->geffnet) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from torchvision->geffnet) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\serge\\miniforge3\\lib\\site-packages (from jinja2->torch>=1.4->geffnet) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install geffnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import geffnet\n",
    "\n",
    "# Словарь для сопоставления классов с индексами\n",
    "LABEL_MAP = {\n",
    "    0: \"AK\", 1: \"BCC\", 2: \"BKL\", 3: \"DF\", 4: \"SCC\", \n",
    "    5: \"VASC\", 6: \"melanoma\", 7: \"nevus\", 8: \"unknown\"\n",
    "}\n",
    "\n",
    "class Enetv2(torch.nn.Module):\n",
    "    def __init__(self, out_dim=9, n_meta_features=0, load_pretrained=False):\n",
    "        super(Enetv2, self).__init__()\n",
    "        self.n_meta_features = n_meta_features\n",
    "        self.enet = geffnet.create_model(\"efficientnet_b7\", pretrained=load_pretrained)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "        in_ch = self.enet.classifier.in_features\n",
    "        self.myfc = torch.nn.Linear(in_ch, out_dim)\n",
    "        self.enet.classifier = torch.nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        x = self.enet(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, x_meta=None):\n",
    "        x = self.extract(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.myfc(self.dropout(x))\n",
    "        return x\n",
    "\n",
    "def load_enetv(model_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Загружает модель Enetv2.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Путь к файлу модели (.pth).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Модель и устройство (CPU).\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = Enetv2()\n",
    "    model = model.to(device)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    state_dict = {k.replace(\"module.\", \"\"): state_dict[k] for k in state_dict.keys()}\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.eval()\n",
    "    return model, device\n",
    "\n",
    "def transform_image(image: Image.Image, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Преобразует изображение в тензор для модели.\n",
    "    \n",
    "    Args:\n",
    "        image (PIL.Image): Изображение.\n",
    "        device (torch.device): Устройство (CPU).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Тензор изображения.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "def predict_single_image(image_path: str, model_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Получает предсказание для одного изображения.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Путь к изображению.\n",
    "        model_path (str): Путь к модели.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Вероятности для каждого класса.\n",
    "    \"\"\"\n",
    "    # Загрузка модели\n",
    "    model, device = load_enetv(model_path)\n",
    "    \n",
    "    # Загрузка и преобразование изображения\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    tensor = transform_image(image, device)\n",
    "    \n",
    "    # Предсказание\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor)\n",
    "        probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    # Формирование результата\n",
    "    result = {LABEL_MAP[i]: float(probs[i]) for i in range(len(LABEL_MAP))}\n",
    "    return result\n",
    "\n",
    "def predict_folder_images(folder_path: str, model_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Получает предсказания для всех изображений в папке.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Путь к папке с изображениями.\n",
    "        model_path (str): Путь к модели.\n",
    "    \n",
    "    Returns:\n",
    "        list: Список результатов для каждого изображения.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    model, device = load_enetv(model_path)\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                result = predict_single_image(image_path, model_path)\n",
    "                results.append({\"filename\": filename, \"predictions\": result})\n",
    "                print(f\"Processed: {filename}, Predictions: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Пример использования:\n",
    "# 1. Для одного изображения:\n",
    "# result = predict_single_image(\"path/to/image.jpg\", \"path/to/model.pth\")\n",
    "# print(result)\n",
    "\n",
    "# 2. Для папки с изображениями:\n",
    "# results = predict_folder_images(\"path/to/folder\", \"path/to/model.pth\")\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serge\\AppData\\Local\\Temp\\ipykernel_18088\\3809344494.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AK': 0.007712574675679207, 'BCC': 0.04195880889892578, 'BKL': 0.10691017657518387, 'DF': 0.001361585920676589, 'SCC': 0.0038253762759268284, 'VASC': 0.005354320164769888, 'melanoma': 0.0859205573797226, 'nevus': 0.10472423583269119, 'unknown': 0.642232358455658}\n"
     ]
    }
   ],
   "source": [
    "result = predict_single_image(\"pic/1.jpeg\", \"model.pth\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
